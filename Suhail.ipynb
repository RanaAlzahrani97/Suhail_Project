{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import sys\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from two_lists_similarity import Calculate_Similarity as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading all files \n",
    "data = pd.read_csv('listing.csv', encoding = 'latin-1')\n",
    "desc = pd.read_csv('descrption.csv', encoding = 'latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding = 'latin-1')\n",
    "data2 = pd.read_csv('Users.csv', index_col=\"Name\")\n",
    "data3 = pd.read_csv(\"descrption.csv\", index_col=\"ID\")\n",
    "data4 = pd.read_csv('descrption.csv', index_col=\"Name\")\n",
    "data5 = pd.read_csv(\"Users.csv\", index_col=\"Name\")\n",
    "data6 = pd.read_csv(\"Object.csv\", index_col=\"ID\")\n",
    "object = pd.read_csv(\"Object.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face recognition using live camera \n",
    "j=0\n",
    "userName=''\n",
    "Encodings=[]\n",
    "Names=[]\n",
    "dispW=640\n",
    "dispH=480\n",
    "flip=2\n",
    " \n",
    "with open('train.pkl','rb') as f:\n",
    "    Names=pickle.load(f)\n",
    "    Encodings=pickle.load(f)\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "#for Rasperrypi Camera v2 \n",
    "camSet='nvarguscamerasrc !  video/x-raw(memory:NVMM), width=3264, height=2464, format=NV12, framerate=21/1 ! nvvidconv flip-method='+str(flip)+' ! video/x-raw, width='+str(dispW)+', height='+str(dispH)+', format=BGRx ! videoconvert ! video/x-raw, format=BGR ! videobalance  contrast=1.5 brightness=-.3 saturation=1.2 ! appsink  '\n",
    "cam= cv2.VideoCapture(camSet)\n",
    " \n",
    "while True:\n",
    " \n",
    "    _,frame=cam.read()\n",
    "    frameSmall=cv2.resize(frame,(0,0),fx=.25,fy=.25)\n",
    "    frameRGB=cv2.cvtColor(frameSmall,cv2.COLOR_BGR2RGB)\n",
    "    facePositions=face_recognition.face_locations(frameRGB,model='cnn')\n",
    "    allEncodings=face_recognition.face_encodings(frameRGB,facePositions)\n",
    "    for (top,right,bottom,left),face_encoding in zip(facePositions,allEncodings):\n",
    "        name='Unkown Person'\n",
    "        matches=face_recognition.compare_faces(Encodings,face_encoding)\n",
    "        if True in matches:\n",
    "            first_match_index=matches.index(True)\n",
    "            name=Names[first_match_index]\n",
    "            userName=name\n",
    "        top=top*4\n",
    "        right=right*4\n",
    "        bottom=bottom*4\n",
    "        left=left*4\n",
    "        cv2.rectangle(frame,(left,top),(right, bottom),(0,0,255),2)\n",
    "        cv2.putText(frame,name,(left,top-6),font,.75,(0,0,255),2)\n",
    "    cv2.imshow('Picture',frame)\n",
    "    cv2.moveWindow('Picture',0,0)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    " \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------object detection using live camera ------\n",
    "\n",
    "import jetson.inference\n",
    "import jetson.utils\n",
    "\n",
    "net = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)\n",
    "camera = jetson.utils.gstCamera()\n",
    "display = jetson.utils.glDisplay()\n",
    "\n",
    "while display.IsOpen():\n",
    "\timg, width, height = camera.CaptureRGBA()\n",
    "\tdetections = net.Detect(img, width, height)\n",
    "\tdisplay.RenderOnce(img, width, height)\n",
    "\tdisplay.SetTitle(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------object detection using images--------------\n",
    "\n",
    "import jetson.inference\n",
    "import jetson.utils\n",
    "\n",
    "\n",
    "# parse the command line\n",
    "parser = argparse.ArgumentParser(description=\"Locate objects in a live camera stream using an object detection DNN.\", \n",
    "                                 formatter_class=argparse.RawTextHelpFormatter, epilog=jetson.inference.detectNet.Usage() +\n",
    "                                 jetson.utils.videoSource.Usage() + jetson.utils.videoOutput.Usage() + jetson.utils.logUsage())\n",
    "\n",
    "parser.add_argument(\"input_URI\", type=str, default=\"\", nargs='?', help=\"URI of the input stream\")\n",
    "parser.add_argument(\"output_URI\", type=str, default=\"\", nargs='?', help=\"URI of the output stream\")\n",
    "parser.add_argument(\"--network\", type=str, default=\"ssd-inception-v2\", help=\"pre-trained model to load (see below for options)\")\n",
    "parser.add_argument(\"--overlay\", type=str, default=\"box,labels,conf\", help=\"detection overlay flags (e.g. --overlay=box,labels,conf)\\nvalid combinations are:  'box', 'labels', 'conf', 'none'\")\n",
    "parser.add_argument(\"--threshold\", type=float, default=0.5, help=\"minimum detection threshold to use\") \n",
    "\n",
    "is_headless = [\"--headless\"] if sys.argv[0].find('console.py') != -1 else [\"\"]\n",
    "\n",
    "try:\n",
    "\topt = parser.parse_known_args()[0]\n",
    "except:\n",
    "\tprint(\"\")\n",
    "\tparser.print_help()\n",
    "\tsys.exit(0)\n",
    "\n",
    "# load the object detection network\n",
    "net = jetson.inference.detectNet(opt.network, sys.argv, opt.threshold)\n",
    "\n",
    "# create video sources & outputs\n",
    "input = jetson.utils.videoSource(opt.input_URI, argv=sys.argv)\n",
    "output = jetson.utils.videoOutput(opt.output_URI, argv=sys.argv+is_headless)\n",
    "detectionIDs = list()\n",
    "# process frames until the user exitsdetectionArray =  list()\n",
    "while True:\n",
    "\t# capture the next image\n",
    "\timg = input.Capture()\n",
    "\n",
    "\t# detect objects in the image (with overlay)\n",
    "\tdetections = net.Detect(img, overlay=opt.overlay)\n",
    "\t\n",
    "\n",
    "\t# print the detections\n",
    "\tprint(\"detected {:d} objects in image\".format(len(detections)))\n",
    "    \n",
    "\tfor detection in detections:\n",
    "\t\tprint(detection)\n",
    "\n",
    "\t# render the image\n",
    "\toutput.Render(img)\n",
    "\n",
    "\n",
    "\t# update the title bar\n",
    "\toutput.SetStatus(\"{:s} | Network {:.0f} FPS\".format(opt.network, net.GetNetworkFPS()))\n",
    "\n",
    "\t# print out performance info\n",
    "\tnet.PrintProfilerTimes()\n",
    "\n",
    "    for i in range(len(detections)):\n",
    "        detectionIDs.append(detections[i].ClassID)\n",
    "\t\n",
    "\n",
    "\t# exit on input/output EOS\n",
    "\tif not input.IsStreaming() or not output.IsStreaming():\n",
    "\t\tbreak\n",
    "\t\t\n",
    "\n",
    "#__________________________________________________\n",
    "\n",
    "#-- write Interest in user file based on object detection \n",
    "\n",
    "#get object's index from it's ID\n",
    "for i in range(len(detectionIDs)):\n",
    "    index1=0\n",
    "    index2=1\n",
    "    for col in data6.index:\n",
    "        if col == detectionIDs[i]:\n",
    "            break\n",
    "        if index1 <= len(data6):\n",
    "            index1+=1 \n",
    "\n",
    "#get object's name from index \n",
    "    #label=object.iloc[index1, 1]\n",
    "    category=object.iloc[index1,2]\n",
    "    if category!=\"person\":\n",
    "        categories.append(category)\n",
    "\n",
    "    for col in data5.index:\n",
    "        if col == 'Ahmed':\n",
    "            break\n",
    "        if index2 <= len(data5):\n",
    "            index2+=1\n",
    "#write category in user's intrest column \n",
    "f = open('Users.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "mylist = list(reader)\n",
    "f.close()\n",
    "print(categories)\n",
    "mylist[index2][6] = categories\n",
    "my_new_list = open('Users.csv', 'w', newline = '')\n",
    "csv_writer = csv.writer(my_new_list)\n",
    "csv_writer.writerows(mylist)\n",
    "my_new_list.close()\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendation based on distance \n",
    "distance = pd.DataFrame(data, columns=['ID','Distance','Name'])\n",
    "# Sorting and dropping the duplicates\n",
    "sort=distance.sort_values('Distance', ascending=True).drop_duplicates().head(10)\n",
    "print(sort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendation based on history \n",
    "desc_tfidf = TfidfVectorizer(stop_words='english')\n",
    "# filling the missing values with empty string\n",
    "desc['Description'] = desc['Description'].fillna('')\n",
    "# computing TF-IDF matrix required for calculating cosine similarity\n",
    "description_matrix = desc_tfidf.fit_transform(desc['Description'])\n",
    "# Let's check the shape of computed matrix\n",
    "description_matrix.shape\n",
    "# computing cosine similarity matrix using linear_kernal of sklearn\n",
    "cosine_similarity = linear_kernel(description_matrix, description_matrix)\n",
    "indices = pd.Series(desc['Name'].index)\n",
    "\n",
    "def recommend(index, cosine_sim=cosine_similarity):\n",
    "    id = indices[index]\n",
    "    # Get the pairwsie similarity scores of all books compared to that book, \n",
    "    # sorting them and getting top 5\n",
    "    similarity_scores = list(enumerate(cosine_sim[id]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:2]\n",
    "    # Get the books index\n",
    "    index = [i[0] for i in similarity_scores]\n",
    "    # Return the top 5 most similar books using integer-location based indexing (iloc)\n",
    "    return desc['Name'].iloc[index]\n",
    "\n",
    "history = data2.loc[userName][\"History\"]\n",
    "place = data3.loc[history][\"Name\"]\n",
    "print(place)\n",
    "\n",
    "index = 0 # history place's index\n",
    "# iterating over indices\n",
    "for col in data4.index:\n",
    "    if col == place:\n",
    "        break\n",
    "    if index < len(data4):\n",
    "        index+=1\n",
    "#index of history place\n",
    "#print(\"place index\",index)\n",
    "#print(len(data4))\n",
    "\n",
    "if index == len(data4):\n",
    "    print(\"not found\")\n",
    "else:\n",
    "   recoomenderPlaces =recommend(index)\n",
    "   #print(recoomenderPlaces)\n",
    "   #-------------end of recommendation based on history----------\n",
    "\n",
    "   # index of recommender place \n",
    "   index3=0\n",
    "   for col in data4.index:\n",
    "    if col == recoomenderPlaces:\n",
    "        break\n",
    "    if index3 <= len(data4):\n",
    "        index3+=1\n",
    "        print (index3)\n",
    "        placeID=desc.iloc[index3, 0]\n",
    "        print(\"place id \",placeID)\n",
    "\n",
    "        index4=1 # user index\n",
    "\n",
    "    for col in data2.index:\n",
    "        if col == userName:\n",
    "            break\n",
    "        if index4 <= len(data2):\n",
    "          index4+=1\n",
    "\n",
    "    f = open('Users.csv', 'r')\n",
    "    reader = csv.reader(f)\n",
    "    mylist = list(reader)\n",
    "    f.close()\n",
    "    mylist[index4][5] = placeID # write place ID of what we recommend in user's history \n",
    "    my_new_list = open('Users.csv', 'w', newline = '')\n",
    "    csv_writer = csv.writer(my_new_list)\n",
    "    csv_writer.writerows(mylist)\n",
    "    my_new_list.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendation based on similar keyword between user's intrest and Neom Places \n",
    "\n",
    "interest = users.iloc[index4, 6] #[user's index , intrest column No. ] 6= intrest in users tables\n",
    "interestxArray = interest.split(\",\")\n",
    "place = pd.read_csv(\"descrption.csv\", index_col=\"Description\")# what column we want similraty based on  \n",
    "placesArray=[]\n",
    "index5=0\n",
    "for col in place.index5:\n",
    "    if index5 < len(place):\n",
    "        placesArray.append(col)    \n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "interestList = interestxArray\n",
    "PlacesList = placesArray\n",
    "\n",
    "# Create an instance of the class. This is otherwise called as an object \n",
    "csObj = cs(interestList,PlacesList)   \n",
    "#csObj.dissimilar_input_items(similarity_threshold = 0.65)\n",
    "\n",
    "# csObj is now the object of Calculate Similarity class. \n",
    "csObj.fuzzy_match_output(output_csv_name = 'test.csv', output_csv_path = r'C:\\Users\\RanaA\\PycharmProjects\\pythonProject')\n"
   ]
  }
 ]
}